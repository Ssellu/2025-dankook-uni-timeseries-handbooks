{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "067af2cf",
   "metadata": {},
   "source": [
    "# 단변량 모델과 다변량 모델\n",
    "## 1. 다변량과 단변량\n",
    "- **단변량(Univariate)**: 단일 종속 변수(Y)의 시계열 패턴\n",
    "  - 예: 일일 전력 소비량 예측  \n",
    "- **다변량(Multivariate)**: 두 개 이상의 종속 변수(Y) 또는 다수의 독립 변수(X) 간 상호작용을 고려하는 시계열 패턴턴\n",
    "  - 예: 온도, 습도, 기계 가동률을 활용한 전력 수요 예측  \n",
    "\n",
    "| 구분 | 단변량 모델 | 다변량 모델 |  \n",
    "|------|-------------|-------------|  \n",
    "| **입력 변수** | 단일 시계열 | 다중 시계열 또는 외부 변수(외생 변수) 포함 |  \n",
    "| **복잡도** | 낮음 (계산 자원 소요 적음) | 높음 (변수 간 상관관계 모델링 필요) |  \n",
    "| **적용 사례** | 단순 패턴 예측 | 복잡한 시스템의 다차원 상호작용 분석 |  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff6766",
   "metadata": {},
   "source": [
    "## 2. 주요 모델  \n",
    "\n",
    "### **2.1. 단변량 예측 모델**  \n",
    "- **ARIMA/SARIMA**: 시계열의 자기회귀(AR)와 이동평균(MA) 성분을 결합.  \n",
    "- **Exponential Smoothing**: 최근 관측치에 가중치 부여.  \n",
    "- **Prophet**: Facebook 개발, 휴일/이상치 자동 처리.  \n",
    "- **Chronos-forecasting**: Intel의 Analytics Zoo에서 제공하는 시계열 예측 라이브러리로, AutoML 기능을 통해 최적의 하이퍼파라미터와 모델 구조를 자동으로 탐색\n",
    "\n",
    "### **2.2. 다변량 예측 모델**  \n",
    "- **VAR(Vector Autoregression)**: 다변량 시계열의 선형 상호작용 모델링.  \n",
    "- **LSTM with Multiple Inputs**: RNN 기반, 장기 의존성 학습.  \n",
    "- **TFT(Temporal Fusion Transformer)**: Attention 메커니즘으로 변수 중요\n",
    "- **TSMixer**: 시계열 데이터를 위한 MLP 기반 모델로, 간단한 구조와 높은 효율성을 제공.  \n",
    "- **Informer**: Sparse Self-Attention 메커니즘을 활용하여 긴 시계열 데이터의 효율적인 예측 가능.  \n",
    "- **TSRM (Time-Series Relational Modeling)**: 시계열 데이터 간의 관계를 학습하여 다변량 시계열 예측 성능을 향상.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19da376",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 기반 주요 다변량 시계열 모델\n",
    "\n",
    "### 1. **LSTM with Multiple Inputs**\n",
    "- **방식**: 재귀 신경망을 통한 장기 의존성 학습  \n",
    "- **강점**: 시퀀스 길이 유연성  \n",
    "- **한계**: 계산 비용 대비 정확도 한계  \n",
    "- **적용 분야**: 에너지 소비 패턴 예측\n",
    "\n",
    "### 2. **TFT (Temporal Fusion Transformer)**\n",
    "- **방식**: 어텐션 기반 변수 중요도 가중치 부여  \n",
    "- **강점**: 이종 피처(정적/동적) 통합 처리  \n",
    "- **한계**: 1,000+ 변수 시 확장성 저하  \n",
    "- **적용 분야**: 공급망 수요 예측\n",
    "\n",
    "### 3. **TSMixer**\n",
    "- **방식**: 순수 MLP 구조의 시간/특성 혼합 레이어  \n",
    "- **강점**: 트랜스포머 대비 3배 빠른 추론  \n",
    "- **한계**: 초장기 예측(1,000+ step) 미흡  \n",
    "- **적용 분야**: 실시간 전력 수요 예측\n",
    "\n",
    "### 4. **Informer**\n",
    "- **방식**: ProbSparse 어텐션을 통한 효율적 장기 예측  \n",
    "- **강점**: 10,000+ 길이 시퀀스 처리 가능  \n",
    "- **한계**: 단순 주기성 패턴 재현 어려움  \n",
    "- **적용 분야**: 기상 데이터 장기 예보\n",
    "\n",
    "### 5. **TSRM (Time-Series Relational Modeling)**\n",
    "- **방식**: CNN-어텐션 하이브리드 아키텍처  \n",
    "- **강점**: 누락 데이터 내재적 보정  \n",
    "- **한계**: 소규모 데이터셋 과적합 리스크  \n",
    "- **적용 분야**: 의료 센서 데이터 분석\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550d024",
   "metadata": {},
   "source": [
    "\n",
    "## 1. **LSTM with Multiple Inputs**\n",
    "### 📄 논문\n",
    "- 별도 제시되지 않음 (전통적인 LSTM 확장 아키텍처)\n",
    "### 👨💻 GitHub\n",
    "- [Multistep Input-Output Timeseries](https://github.com/iamarchisha/multistep-io-timeseries): 다변량 입력/출력 처리 LSTM 구현\n",
    "- [Apple/Google 주가 예측](https://github.com/SevilayMuni/Multivariate-TimeSeries-Forecast-LSTM-Apple-Google-Stocks): 실제 금융 데이터 적용 사례\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **TFT (Temporal Fusion Transformer)**\n",
    "### 📄 논문\n",
    "- [Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting](https://arxiv.org/abs/1912.09363) (AAAI 2021)\n",
    "### 👨💻 GitHub\n",
    "- [공식](https://github.com/google-research/google-research/tree/master/tft)\n",
    "- [PyTorch 버전](https://github.com/mattsherar/Temporal_Fusion_Transform)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **TSMixer**\n",
    "### 📄 논문\n",
    "- [TSMixer: An All-MLP Architecture for Time Series Forecasting](https://arxiv.org/abs/2303.06053) (Google Research)\n",
    "### 👨💻 GitHub\n",
    "- [PyTorch 공식 구현체](https://github.com/ditschuk/pytorch-tsmixer)\n",
    "- [경량화 버전](https://github.com/smrfeld/tsmixer-pytorch)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. **Informer**\n",
    "### 📄 논문\n",
    "- [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436) (AAAI 2021 Best Paper)\n",
    "### 👨💻 GitHub\n",
    "- [공식 코드베이스](https://github.com/zhouhaoyi/Informer2020)\n",
    "- [관련 프로젝트 모음](https://github.com/topics/informer?l=python)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. **TSRM (Time-Series Relational Modeling)**\n",
    "### 📄 논문\n",
    "- [TSRM: A Lightweight Temporal Feature Encoding Architecture](https://arxiv.org/pdf/2504.18878.pdf) (2025)\n",
    "### 👨💻 GitHub\n",
    "- [공식 구현 리포지토리](https://github.com/RobertLeppich/TSRM)\n",
    "\n",
    "---\n",
    "\n",
    "## 비교 테이블\n",
    "| 모델          | 논문 링크                                                                 | GitHub                                                                 |\n",
    "|---------------|--------------------------------------------------------------------------|------------------------------------------------------------------------|\n",
    "| LSTM          | -                                                                        | [링크](https://github.com/iamarchisha/multistep-io-timeseries)       |\n",
    "| TFT           | [arXiv:1912.09363](https://arxiv.org/abs/1912.09363)                     | [링크](https://github.com/mattsherar/Temporal_Fusion_Transform)       |\n",
    "| TSMixer       | [arXiv:2303.06053](https://arxiv.org/abs/2303.06053)                     | [링크](https://github.com/ditschuk/pytorch-tsmixer)                   |\n",
    "| Informer      | [arXiv:2012.07436](https://arxiv.org/abs/2012.07436)                     | [링크](https://github.com/zhouhaoyi/Informer2020)                     |\n",
    "| TSRM          | [arXiv:2504.18878](https://arxiv.org/pdf/2504.18878.pdf)                 | [링크](https://github.com/RobertLeppich/TSRM)                         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d8d3d",
   "metadata": {},
   "source": [
    "\n",
    "## 종합 평가 매트릭스\n",
    "\n",
    "| 모델          | 처리 변수 수 | 최대 시퀀스 길이 | 실시간 처리 | 비선형성 대응 |  \n",
    "|---------------|--------------|------------------|-------------|---------------|  \n",
    "| VAR           | 10~50        | 500              | △           | ×             |  \n",
    "| LSTM          | 100~500      | 1,000            | ○           | ○             |  \n",
    "| TFT           | 50~200       | 2,000            | △           | ◎             |  \n",
    "| TSMixer       | 200~1,000    | 512              | ◎           | ○             |  \n",
    "| Informer      | 100~300      | 10,000           | △           | ◎             |  \n",
    "| TSRM          | 50~500       | 2,048            | ○           | ◎             |  \n",
    "\n",
    "**◎: 우수 ○: 보통 △: 제한적 ×: 미지원**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c510f6",
   "metadata": {},
   "source": [
    "\n",
    "## 모델 선택 가이드라인\n",
    "1. **실시간성 요구**: TSMixer > LSTM > TSRM  \n",
    "2. **초장기 예측**: Informer > TFT > TSRM  \n",
    "3. **변수 복잡도**: TSMixer > TSRM > TFT  \n",
    "4. **해석 가능성**: VAR > TFT > TSMixer  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b597b8",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.1.2. 다변량(Multivariate) 모델\n",
    "- **정의**\n",
    "- **주요 모델**\n",
    "  \n",
    "- **1.1 단변량 vs 다변량 모델 핵심 차이점**  \n",
    "  - 단변량: ARIMA, Prophet의 산업 적용 한계점  \n",
    "  - 다변량: Informer, Autoformer의 시계열 장기 의존성 해결 전략  \n",
    "- **1.2 스마트팩토리 전력 데이터 특화 모델**  \n",
    "  - N-BEATS의 Interpretable한 계층 구조  \n",
    "  - TFT(Temporal Fusion Transformer)의 변수 간 상호작용 모델링  \n",
    "- **1.3 실시간 에지 컴퓨팅 최적화 기법**  \n",
    "  - LightGBM + DeepAR 하이브리드 아키텍처  \n",
    "  - 모델 경량화를 위한 Knowledge Distillation 적용 사례\n",
    "  \n",
    "#### **2. Forecasting 딥러닝 모델링 실습**  \n",
    "- **2.1 데이터 전처리 워크플로우**  \n",
    "  - 시계열 정규화(Min-Max vs Z-Score)  \n",
    "  - 공장 휴일/비가동 시간 마스킹 기법  \n",
    "- **2.2 Multivariate Input 모델링 전략**  \n",
    "  - CNN-LSTM Hybrid 구조의 특징 추출  \n",
    "  - Attention 기반 변수 중요도 가시화 실습  \n",
    "- **2.3 실전 프로젝트 케이스 스터디**  \n",
    "  - 전력 소비 패턴과 기계 가동률의 상관관계 분석  \n",
    "\n",
    "---\n",
    "\n",
    "### [1시간: AI 모델 성능 평가, 트러블 슈팅]  \n",
    "#### **1. 성능 평가 고급 기법**  \n",
    "- **1.1 다변량 평가 지표 심화**  \n",
    "  - CRPS(Continuous Ranked Probability Score)를 활용한 확률적 예측 검증  \n",
    "  - MASE(Mean Absolute Scaled Error)의 계절성 조정 계산법  \n",
    "- **1.2 예측 구간 시각화 실습**  \n",
    "  - Quantile Regression을 이용한 95% 신뢰구간 생성  \n",
    "  - Plotly를 활용한 Interactive 불확실성 시각화  \n",
    "\n",
    "#### **2. 트러블슈팅 핵심 전략**  \n",
    "- **2.1 추세 반영 실패 진단 매트릭스**  \n",
    "  - STL 분해(Seasonal-Trend Decomposition)를 이용한 잔차 분석  \n",
    "  - Gradient Boosted Trees의 Feature Importance 역추적  \n",
    "- **2.2 하이퍼파라미터 최적화 워크샵**  \n",
    "  - Optuna를 활용한 Bayesian Optimization 자동화 파이프라인  \n",
    "  - Early Stopping과 Pruning의 적정 임계값 설정 가이드  \n",
    "\n",
    "#### **3. 실전 배포 환경 대응**  \n",
    "- **3.1 Concept Drift 감지 시스템**  \n",
    "  - ADWIN(Adaptive Windowing) 알고리즘 구현  \n",
    "  - 재학습 주기 최적화를 위한 모니터링 설계  \n",
    "- **3.2 에지 디바이스 최적화**  \n",
    "  - TensorRT를 이용한 ONNX 모델 변환 실습  \n",
    "  - 전력 소모량과 예측 정확도 Trade-off 분석  \n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
